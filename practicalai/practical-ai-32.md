Relevant learning resources:

- Jay Alammar "Illustrated" blog articles:
    - [The illustrated transformer](https://jalammar.github.io/illustrated-transformer/)
    - [The illustrated BERT, elmo, and co](http://jalammar.github.io/illustrated-bert/)
- Machine Learning Explained blog:
    - [An In-Depth Tutorial to AllenNLP (From Basics to ELMo and BERT)](http://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/)
    - [Paper Dissected: “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding” Explained](http://mlexplained.com/2019/01/07/paper-dissected-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-explained/)

References/notes:

- [GPT-2 blog post from OpenAI](https://blog.openai.com/better-language-models/)
- [GPT-2 Paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
- [GPT-2 GitHub Repo](https://github.com/openai/gpt-2)
- [GPT-2 PyTorch implementation](https://github.com/huggingface/pytorch-pretrained-BERT)
- [Episode 22 of Practical AI about BERT](https://changelog.com/practicalai/22)
- [OpenAI’s GPT-2: the model, the hype, and the controversy (towardsdatascience)](https://towardsdatascience.com/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8)
- [The AI Text Generator That's Too Dangerous to Make Public (Wired)](https://www.wired.com/story/ai-text-generator-too-dangerous-to-make-public/)
- [Transformer paper](https://arxiv.org/pdf/1706.03762.pdf)
- [Preparing for malicious uses of AI (OpenAI blog)](https://blog.openai.com/preparing-for-malicious-uses-of-ai/)